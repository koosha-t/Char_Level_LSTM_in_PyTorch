{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Level LSTM in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Statistical Language Model__: A trained model to predict the next word/character given all previous words/characters.\n",
    "\n",
    "__Character-Level Language Model__: The main task of the char-level language model is to predict the next character given all previous characters in a sequence of data, i.e. generates text character by character. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/anna.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.\\n\\nEverything was in confusion in the Oblonskys' house. The wife had\\ndiscovered that the husband was carrying on an intrigue with a French\\ngirl, who had been a governess in their family, and she had announced to\\nher husband that she could not go on living in the same house with him.\\nThis position of affairs had now lasted three days, and not only the\\nhusband and wife themselves, but all the members of their family and\\nhousehold, were painfully conscious of it. Every person in the house\\nfelt that there was no sense in their living together, and that the\\nstray people brought together by chance in any inn had more in common\\nwith one another than they, the members of the family and household of\\nthe Oblonskys. The wife did not leave her own room, the husband had not\\nbeen at home for three days. The children ran wild all over the house;\\nthe English governess quarreled with the housekeeper, and wrote to a\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encoding the text ## \n",
    "chars = tuple(set(text))\n",
    "int2char = dict(enumerate(chars))\n",
    "char2int = {ch:ii for ii,ch in int2char.items()}\n",
    "encoded = np.array([char2int[ch] for ch in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 35, 77, 44, 76, 18, 20,  4, 10, 55, 55, 55, 17, 77, 44, 44, 32,\n",
       "        4, 49, 77, 53, 59, 21, 59, 18, 26,  4, 77, 20, 18,  4, 77, 21, 21,\n",
       "        4, 77, 21, 59, 37, 18, 66,  4, 18, 51, 18, 20, 32,  4, 52, 73, 35,\n",
       "       77, 44, 44, 32,  4, 49, 77, 53, 59, 21, 32,  4, 59, 26,  4, 52, 73,\n",
       "       35, 77, 44, 44, 32,  4, 59, 73,  4, 59, 76, 26,  4, 27, 78, 73, 55,\n",
       "       78, 77, 32, 63, 55, 55, 13, 51, 18, 20, 32, 76, 35, 59, 73])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(arr):\n",
    "\n",
    "    n_labels = max(arr.flatten()) + 1\n",
    "    \n",
    "    one_hot = np.zeros(shape = (np.multiply(*arr.shape) , n_labels))\n",
    "    \n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1\n",
    "    \n",
    "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = np.array([[1,2,3,7],[5,3,2,8]])\n",
    "one_hot = one_hot_encode(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Training mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N: batch size\n",
    "# M: sequence length\n",
    "# K: total number of batches\n",
    "\n",
    "def get_batches(arr, batch_size, seq_length):\n",
    "    \n",
    "    # Number of matches we can make from the input array\n",
    "    n_batches = len(arr) // (batch_size * seq_length)\n",
    "    \n",
    "    # keeping enoough character to make full batches\n",
    "    arr = arr[:n_batches * batch_size * seq_length]\n",
    "    \n",
    "    arr = arr.reshape((batch_size, -1))\n",
    "    \n",
    "    # iterating over the batches\n",
    "    for n in range(0, arr.shape[1] , seq_length):\n",
    "        x = arr[:, n:n+seq_length]\n",
    "        y = np.zeros_like(x)\n",
    "        try:\n",
    "            y[:,:-1], y[:,-1] = x[:, 1:], arr[:, n+seq_length]\n",
    "        except IndexError:\n",
    "            y[:,:-1], y[:,-1] = x[:, 1:], arr[:,0]\n",
    "        \n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the get_batch function\n",
    "\n",
    "batches = get_batches(encoded, 8, 50)\n",
    "x, y = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 6, 35, 77, 44, 76, 18, 20,  4, 10, 55, 55, 55, 17, 77, 44, 44,\n",
       "         32,  4, 49, 77, 53, 59, 21, 59, 18, 26,  4, 77, 20, 18,  4, 77,\n",
       "         21, 21,  4, 77, 21, 59, 37, 18, 66,  4, 18, 51, 18, 20, 32,  4,\n",
       "         52, 73],\n",
       "        [26, 27, 73,  4, 76, 35, 77, 76,  4, 77, 76, 76, 20, 77, 60, 76,\n",
       "         18, 34,  4, 35, 18, 20,  4, 77, 76, 76, 18, 73, 76, 59, 27, 73,\n",
       "          4, 78, 77, 26,  4, 35, 18, 20,  4, 35, 52, 26,  0, 77, 73, 34,\n",
       "         63,  4],\n",
       "        [18, 73, 34,  4, 27, 20,  4, 77,  4, 49, 27, 18, 82,  4, 35, 18,\n",
       "          4, 77, 51, 27, 59, 34, 18, 34,  4, 35, 59, 26,  4, 49, 77, 76,\n",
       "         35, 18, 20, 63,  4, 17, 18, 55, 21, 27, 27, 37, 18, 34,  4, 20,\n",
       "         27, 52],\n",
       "        [26,  4, 76, 35, 18,  4, 60, 35, 59, 18, 49,  4, 76, 35, 27, 52,\n",
       "         72, 35,  4, 35, 59, 34, 34, 18, 73, 55, 59, 73, 76, 18, 20, 18,\n",
       "         26, 76,  4, 27, 49,  4, 35, 59, 26,  4, 21, 59, 49, 18, 82,  4,\n",
       "         27, 49],\n",
       "        [ 4, 26, 77, 78,  4, 35, 18, 20,  4, 76, 18, 77, 20,  1, 26, 76,\n",
       "         77, 59, 73, 18, 34, 82,  4, 44, 59, 76, 59, 49, 52, 21, 82,  4,\n",
       "         26, 78, 18, 18, 76,  4, 49, 77, 60, 18, 82, 55, 53, 59, 26, 18,\n",
       "         20, 77],\n",
       "        [60, 52, 26, 26, 59, 27, 73,  4, 77, 73, 34,  4, 77, 73, 77, 21,\n",
       "         32, 26, 59, 26, 82,  4, 78, 77, 26,  4, 59, 73,  4, 44, 20, 59,\n",
       "         73, 60, 59, 44, 21, 18,  4, 34, 59, 26, 77, 72, 20, 18, 18, 77,\n",
       "          0, 21],\n",
       "        [ 4, 54, 73, 73, 77,  4, 35, 77, 34,  4, 26, 77, 59, 34,  4, 76,\n",
       "         35, 77, 76,  4, 29, 27, 21, 21, 32,  4, 78, 27, 52, 21, 34,  4,\n",
       "         18, 65, 60, 52, 26, 18,  4, 59, 76, 63,  4, 54, 73, 34,  4, 76,\n",
       "         35, 59],\n",
       "        [11,  0, 21, 27, 73, 26, 37, 32, 63,  4, 70, 36, 52, 76,  4, 64,\n",
       "         76, 35, 18, 32, 64,  4, 60, 77, 73, 73, 27, 76,  4, 72, 20, 77,\n",
       "         26, 44,  4, 76, 35, 77, 76, 82, 55, 64, 76, 35, 18, 32, 64,  4,\n",
       "         77, 20]]),\n",
       " array([[35, 77, 44, 76, 18, 20,  4, 10, 55, 55, 55, 17, 77, 44, 44, 32,\n",
       "          4, 49, 77, 53, 59, 21, 59, 18, 26,  4, 77, 20, 18,  4, 77, 21,\n",
       "         21,  4, 77, 21, 59, 37, 18, 66,  4, 18, 51, 18, 20, 32,  4, 52,\n",
       "         73, 35],\n",
       "        [27, 73,  4, 76, 35, 77, 76,  4, 77, 76, 76, 20, 77, 60, 76, 18,\n",
       "         34,  4, 35, 18, 20,  4, 77, 76, 76, 18, 73, 76, 59, 27, 73,  4,\n",
       "         78, 77, 26,  4, 35, 18, 20,  4, 35, 52, 26,  0, 77, 73, 34, 63,\n",
       "          4, 70],\n",
       "        [73, 34,  4, 27, 20,  4, 77,  4, 49, 27, 18, 82,  4, 35, 18,  4,\n",
       "         77, 51, 27, 59, 34, 18, 34,  4, 35, 59, 26,  4, 49, 77, 76, 35,\n",
       "         18, 20, 63,  4, 17, 18, 55, 21, 27, 27, 37, 18, 34,  4, 20, 27,\n",
       "         52, 73],\n",
       "        [ 4, 76, 35, 18,  4, 60, 35, 59, 18, 49,  4, 76, 35, 27, 52, 72,\n",
       "         35,  4, 35, 59, 34, 34, 18, 73, 55, 59, 73, 76, 18, 20, 18, 26,\n",
       "         76,  4, 27, 49,  4, 35, 59, 26,  4, 21, 59, 49, 18, 82,  4, 27,\n",
       "         49,  4],\n",
       "        [26, 77, 78,  4, 35, 18, 20,  4, 76, 18, 77, 20,  1, 26, 76, 77,\n",
       "         59, 73, 18, 34, 82,  4, 44, 59, 76, 59, 49, 52, 21, 82,  4, 26,\n",
       "         78, 18, 18, 76,  4, 49, 77, 60, 18, 82, 55, 53, 59, 26, 18, 20,\n",
       "         77,  0],\n",
       "        [52, 26, 26, 59, 27, 73,  4, 77, 73, 34,  4, 77, 73, 77, 21, 32,\n",
       "         26, 59, 26, 82,  4, 78, 77, 26,  4, 59, 73,  4, 44, 20, 59, 73,\n",
       "         60, 59, 44, 21, 18,  4, 34, 59, 26, 77, 72, 20, 18, 18, 77,  0,\n",
       "         21, 18],\n",
       "        [54, 73, 73, 77,  4, 35, 77, 34,  4, 26, 77, 59, 34,  4, 76, 35,\n",
       "         77, 76,  4, 29, 27, 21, 21, 32,  4, 78, 27, 52, 21, 34,  4, 18,\n",
       "         65, 60, 52, 26, 18,  4, 59, 76, 63,  4, 54, 73, 34,  4, 76, 35,\n",
       "         59, 26],\n",
       "        [ 0, 21, 27, 73, 26, 37, 32, 63,  4, 70, 36, 52, 76,  4, 64, 76,\n",
       "         35, 18, 32, 64,  4, 60, 77, 73, 73, 27, 76,  4, 72, 20, 77, 26,\n",
       "         44,  4, 76, 35, 77, 76, 82, 55, 64, 76, 35, 18, 32, 64,  4, 77,\n",
       "         20, 18]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_on_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_on_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, chars, n_hidden = 256, n_layers=2, drop_prob=0.5, lr=0.001):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        self.chars = chars\n",
    "        \n",
    "        self.int2chars = dict(enumerate(self.chars))\n",
    "        self.char2int = {ch : ii for ii,ch in self.int2chars.items()}\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = len(self.chars), hidden_size = n_hidden,  num_layers = n_layers, \\\n",
    "                             dropout = self.drop_prob, batch_first = True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(self.drop_prob)\n",
    "        \n",
    "        self.fc = nn.Linear(self.n_hidden, len(self.chars))\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        \n",
    "        r_output, hidden = self.lstm(x, hidden)\n",
    "        out = self.dropout(r_output)\n",
    "        out = out.contiguous().view(-1, self.n_hidden)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        # creating two new tensors with size n_layers * batch_size * n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of the LSTM\n",
    "        \n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if(train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "            \n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "        \n",
    "        return hidden\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, data, epochs=10, batch_size=10, seq_length=50, lr=0.001, clip=5, \\\n",
    "          val_frac=0.1, print_every=10):\n",
    "    '''\n",
    "        Arguments:\n",
    "            net: CharRNN network\n",
    "            data: text data to train the network\n",
    "            epochs: number of epochs\n",
    "            batch_size: number of mini-sequences per mini-batch\n",
    "            seq_length: Number of character steps per mini-batch\n",
    "            lr: learning rate\n",
    "            clip: gradient clipping\n",
    "            val_frac: Fraction of data to hold out for validation\n",
    "            print_every: number of steps for printing training and validation\n",
    "    '''\n",
    "    \n",
    "    net.train()\n",
    "    \n",
    "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    criterio = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # creating training and validation data\n",
    "    val_idx = int(len(data) * (1 - val_frac))\n",
    "    data , val_data = data[:val_idx], data[val_idx]\n",
    "    \n",
    "    if train_on_gpu:\n",
    "        net.cuda()\n",
    "        \n",
    "    counter = 0\n",
    "    n_chars = len(net.chars)\n",
    "    for e in range(epochs):\n",
    "        h = net.init_hidden(batch_size)\n",
    "        \n",
    "        for x, y in get_batches(data, batch_size, seq_length):\n",
    "            counter += 1\n",
    "            x = one_hot_encode(x)\n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            \n",
    "            if train_on_gpu:\n",
    "                inputs , targets = inputs.cuda(), targets.cuda()\n",
    "                \n",
    "            #creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            h = tuple([each.data for each in h])\n",
    "            \n",
    "            net.zero_grad()\n",
    "            \n",
    "            output, h = net(inputs, h)\n",
    "            \n",
    "            loss = criterion(output, targets.view(batch_size*seq_length))\n",
    "            loss.backward()\n",
    "            \n",
    "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            opt.step()\n",
    "            \n",
    "            if counter % print_every == 0:\n",
    "                val_h = net.init_hidden(batch_size)\n",
    "                val_losses=[]\n",
    "                net.eval()\n",
    "                for x,y in get_batches(val_data, batch_size, seq_length):\n",
    "                    x = one_hot_encode(x)\n",
    "                    x,y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "                    \n",
    "                    val_h = tuple([each.data for each in val_h])\n",
    "                    \n",
    "                    inputs, targets = x,y\n",
    "                    if(train_on_gpu):\n",
    "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                        \n",
    "                    output, val_h = net(inputs, val_h)\n",
    "                    val_loss = criterion0(output, targets.view(batch_size*seq_length))\n",
    "                    \n",
    "                    val_losses.append(val_loss.item())\n",
    "            \n",
    "            net.train()\n",
    "            \n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.4f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharRNN(\n",
      "  (lstm): LSTM(83, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=83, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 512\n",
    "n_layers=2\n",
    "\n",
    "net = CharRNN(chars, n_hidden, n_layers)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "seq_length = 100\n",
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_BAD_PARAM",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-7b14b0409a17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train(net, encoded, epochs=n_epochs, batch_size= batch_size, \\\n\u001b[0m\u001b[1;32m      2\u001b[0m       seq_length= seq_length, lr=0.001, print_every=10)\n",
      "\u001b[0;32m<ipython-input-26-07920f310738>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, data, epochs, batch_size, seq_length, lr, clip, val_frac, print_every)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-3e8d9af497d7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mr_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    577\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    578\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_BAD_PARAM"
     ]
    }
   ],
   "source": [
    "\n",
    "train(net, encoded, epochs=n_epochs, batch_size= batch_size, \\\n",
    "      seq_length= seq_length, lr=0.001, print_every=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
