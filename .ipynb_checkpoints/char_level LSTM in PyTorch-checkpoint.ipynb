{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Level LSTM in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Statistical Language Model__: A trained model to predict the next word/character given all previous words/characters.\n",
    "\n",
    "__Character-Level Language Model__: The main task of the char-level language model is to predict the next character given all previous characters in a sequence of data, i.e. generates text character by character. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/anna.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.\\n\\nEverything was in confusion in the Oblonskys' house. The wife had\\ndiscovered that the husband was carrying on an intrigue with a French\\ngirl, who had been a governess in their family, and she had announced to\\nher husband that she could not go on living in the same house with him.\\nThis position of affairs had now lasted three days, and not only the\\nhusband and wife themselves, but all the members of their family and\\nhousehold, were painfully conscious of it. Every person in the house\\nfelt that there was no sense in their living together, and that the\\nstray people brought together by chance in any inn had more in common\\nwith one another than they, the members of the family and household of\\nthe Oblonskys. The wife did not leave her own room, the husband had not\\nbeen at home for three days. The children ran wild all over the house;\\nthe English governess quarreled with the housekeeper, and wrote to a\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encoding the text ## \n",
    "chars = tuple(set(text))\n",
    "int2char = dict(enumerate(chars))\n",
    "char2int = {ch:ii for ii,ch in int2char.items()}\n",
    "encoded = np.array([char2int[ch] for ch in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  3, 33, 65, 68,  4, 22, 60, 47, 55, 55, 55, 62, 33, 65, 65, 76,\n",
       "       60, 57, 33, 48, 32, 18, 32,  4, 67, 60, 33, 22,  4, 60, 33, 18, 18,\n",
       "       60, 33, 18, 32, 58,  4, 23, 60,  4, 44,  4, 22, 76, 60, 46, 36,  3,\n",
       "       33, 65, 65, 76, 60, 57, 33, 48, 32, 18, 76, 60, 32, 67, 60, 46, 36,\n",
       "        3, 33, 65, 65, 76, 60, 32, 36, 60, 32, 68, 67, 60, 25, 80, 36, 55,\n",
       "       80, 33, 76,  9, 55, 55, 69, 44,  4, 22, 76, 68,  3, 32, 36])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(arr):\n",
    "\n",
    "    n_labels = max(arr.flatten()) + 1\n",
    "    \n",
    "    one_hot = np.zeros(shape = (np.multiply(*arr.shape) , n_labels))\n",
    "    \n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1\n",
    "    \n",
    "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = np.array([[1,2,3,7],[5,3,2,8]])\n",
    "one_hot = one_hot_encode(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Training mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N: batch size\n",
    "# M: sequence length\n",
    "# K: total number of batches\n",
    "\n",
    "def get_batches(arr, batch_size, seq_length):\n",
    "    \n",
    "    # Number of matches we can make from the input array\n",
    "    n_batches = len(arr) // (batch_size * seq_length)\n",
    "    \n",
    "    # keeping enoough character to make full batches\n",
    "    arr = arr[:n_batches * batch_size * seq_length]\n",
    "    \n",
    "    arr = arr.reshape((batch_size, -1))\n",
    "    \n",
    "    # iterating over the batches\n",
    "    for n in range(0, arr.shape[1] , seq_length):\n",
    "        x = arr[:, n:n+seq_length]\n",
    "        y = np.zeros_like(x)\n",
    "        try:\n",
    "            y[:,:-1], y[:,-1] = x[:, 1:], arr[:, n+seq_length]\n",
    "        except IndexError:\n",
    "            y[:,:-1], y[:,-1] = x[:, 1:], arr[:,0]\n",
    "        \n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the get_batch function\n",
    "\n",
    "batches = get_batches(encoded, 8, 50)\n",
    "x, y = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  3, 33, 65, 68,  4, 22, 60, 47, 55, 55, 55, 62, 33, 65, 65,\n",
       "         76, 60, 57, 33, 48, 32, 18, 32,  4, 67, 60, 33, 22,  4, 60, 33,\n",
       "         18, 18, 60, 33, 18, 32, 58,  4, 23, 60,  4, 44,  4, 22, 76, 60,\n",
       "         46, 36],\n",
       "        [67, 25, 36, 60, 68,  3, 33, 68, 60, 33, 68, 68, 22, 33, 20, 68,\n",
       "          4,  6, 60,  3,  4, 22, 60, 33, 68, 68,  4, 36, 68, 32, 25, 36,\n",
       "         60, 80, 33, 67, 60,  3,  4, 22, 60,  3, 46, 67, 31, 33, 36,  6,\n",
       "          9, 60],\n",
       "        [ 4, 36,  6, 60, 25, 22, 60, 33, 60, 57, 25,  4, 78, 60,  3,  4,\n",
       "         60, 33, 44, 25, 32,  6,  4,  6, 60,  3, 32, 67, 60, 57, 33, 68,\n",
       "          3,  4, 22,  9, 60, 62,  4, 55, 18, 25, 25, 58,  4,  6, 60, 22,\n",
       "         25, 46],\n",
       "        [67, 60, 68,  3,  4, 60, 20,  3, 32,  4, 57, 60, 68,  3, 25, 46,\n",
       "         64,  3, 60,  3, 32,  6,  6,  4, 36, 55, 32, 36, 68,  4, 22,  4,\n",
       "         67, 68, 60, 25, 57, 60,  3, 32, 67, 60, 18, 32, 57,  4, 78, 60,\n",
       "         25, 57],\n",
       "        [60, 67, 33, 80, 60,  3,  4, 22, 60, 68,  4, 33, 22, 38, 67, 68,\n",
       "         33, 32, 36,  4,  6, 78, 60, 65, 32, 68, 32, 57, 46, 18, 78, 60,\n",
       "         67, 80,  4,  4, 68, 60, 57, 33, 20,  4, 78, 55, 48, 32, 67,  4,\n",
       "         22, 33],\n",
       "        [20, 46, 67, 67, 32, 25, 36, 60, 33, 36,  6, 60, 33, 36, 33, 18,\n",
       "         76, 67, 32, 67, 78, 60, 80, 33, 67, 60, 32, 36, 60, 65, 22, 32,\n",
       "         36, 20, 32, 65, 18,  4, 60,  6, 32, 67, 33, 64, 22,  4,  4, 33,\n",
       "         31, 18],\n",
       "        [60, 14, 36, 36, 33, 60,  3, 33,  6, 60, 67, 33, 32,  6, 60, 68,\n",
       "          3, 33, 68, 60, 77, 25, 18, 18, 76, 60, 80, 25, 46, 18,  6, 60,\n",
       "          4, 75, 20, 46, 67,  4, 60, 32, 68,  9, 60, 14, 36,  6, 60, 68,\n",
       "          3, 32],\n",
       "        [66, 31, 18, 25, 36, 67, 58, 76,  9, 60, 19, 61, 46, 68, 60, 81,\n",
       "         68,  3,  4, 76, 81, 60, 20, 33, 36, 36, 25, 68, 60, 64, 22, 33,\n",
       "         67, 65, 60, 68,  3, 33, 68, 78, 55, 81, 68,  3,  4, 76, 81, 60,\n",
       "         33, 22]]),\n",
       " array([[ 3, 33, 65, 68,  4, 22, 60, 47, 55, 55, 55, 62, 33, 65, 65, 76,\n",
       "         60, 57, 33, 48, 32, 18, 32,  4, 67, 60, 33, 22,  4, 60, 33, 18,\n",
       "         18, 60, 33, 18, 32, 58,  4, 23, 60,  4, 44,  4, 22, 76, 60, 46,\n",
       "         36,  3],\n",
       "        [25, 36, 60, 68,  3, 33, 68, 60, 33, 68, 68, 22, 33, 20, 68,  4,\n",
       "          6, 60,  3,  4, 22, 60, 33, 68, 68,  4, 36, 68, 32, 25, 36, 60,\n",
       "         80, 33, 67, 60,  3,  4, 22, 60,  3, 46, 67, 31, 33, 36,  6,  9,\n",
       "         60, 19],\n",
       "        [36,  6, 60, 25, 22, 60, 33, 60, 57, 25,  4, 78, 60,  3,  4, 60,\n",
       "         33, 44, 25, 32,  6,  4,  6, 60,  3, 32, 67, 60, 57, 33, 68,  3,\n",
       "          4, 22,  9, 60, 62,  4, 55, 18, 25, 25, 58,  4,  6, 60, 22, 25,\n",
       "         46, 36],\n",
       "        [60, 68,  3,  4, 60, 20,  3, 32,  4, 57, 60, 68,  3, 25, 46, 64,\n",
       "          3, 60,  3, 32,  6,  6,  4, 36, 55, 32, 36, 68,  4, 22,  4, 67,\n",
       "         68, 60, 25, 57, 60,  3, 32, 67, 60, 18, 32, 57,  4, 78, 60, 25,\n",
       "         57, 60],\n",
       "        [67, 33, 80, 60,  3,  4, 22, 60, 68,  4, 33, 22, 38, 67, 68, 33,\n",
       "         32, 36,  4,  6, 78, 60, 65, 32, 68, 32, 57, 46, 18, 78, 60, 67,\n",
       "         80,  4,  4, 68, 60, 57, 33, 20,  4, 78, 55, 48, 32, 67,  4, 22,\n",
       "         33, 31],\n",
       "        [46, 67, 67, 32, 25, 36, 60, 33, 36,  6, 60, 33, 36, 33, 18, 76,\n",
       "         67, 32, 67, 78, 60, 80, 33, 67, 60, 32, 36, 60, 65, 22, 32, 36,\n",
       "         20, 32, 65, 18,  4, 60,  6, 32, 67, 33, 64, 22,  4,  4, 33, 31,\n",
       "         18,  4],\n",
       "        [14, 36, 36, 33, 60,  3, 33,  6, 60, 67, 33, 32,  6, 60, 68,  3,\n",
       "         33, 68, 60, 77, 25, 18, 18, 76, 60, 80, 25, 46, 18,  6, 60,  4,\n",
       "         75, 20, 46, 67,  4, 60, 32, 68,  9, 60, 14, 36,  6, 60, 68,  3,\n",
       "         32, 67],\n",
       "        [31, 18, 25, 36, 67, 58, 76,  9, 60, 19, 61, 46, 68, 60, 81, 68,\n",
       "          3,  4, 76, 81, 60, 20, 33, 36, 36, 25, 68, 60, 64, 22, 33, 67,\n",
       "         65, 60, 68,  3, 33, 68, 78, 55, 81, 68,  3,  4, 76, 81, 60, 33,\n",
       "         22,  4]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_on_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_on_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, chars, n_hidden = 256, n_layers=2, drop_prob=0.5, lr=0.001):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        self.chars = chars\n",
    "        \n",
    "        self.int2chars = dict(enumerate(self.chars))\n",
    "        self.char2int = {ch : ii for ii,ch in self.int2chars.items()}\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = len(self.chars), hidden_size = n_hidden,  num_layers = n_layers, \\\n",
    "                             dropout = self.drop_prob, batch_first = True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(self.drop_prob)\n",
    "        \n",
    "        self.fc = nn.Linear(self.n_hidden, len(self.chars))\n",
    "    \n",
    "    def forward(sel, x, hidden):\n",
    "        \n",
    "        r_output, hidden = self.lstm(x, hidden)\n",
    "        out = self.dropout(r_output)\n",
    "        out = out.contiguous().view(-1, self.n_hidden)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
